{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf0d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "from torchvision.models.inception import inception_v3\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9b88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should use same mean and std for inception v3 model in training and testing process\n",
    "# reference web page: https://pytorch.org/hub/pytorch_vision_inception_v3/\n",
    "mean_inception = [0.485, 0.456, 0.406]\n",
    "std_inception = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5d7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(filename):\n",
    "    \"\"\"\n",
    "    Loads an image file into a (height, width, 3) uint8 ndarray.\n",
    "    \"\"\"\n",
    "    return np.asarray(Image.open(filename), dtype=np.uint8)[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56200e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu=2\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")  # you can change the index of cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca023ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score(batch_size=50, resize=True, splits=10):\n",
    "    # Set up dtype\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")  # you can change the index of cuda\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.eval()\n",
    "    up = nn.Upsample(size=(299, 299), mode='bilinear', align_corners=False).to(device)\n",
    "    \n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x).to(device)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x, dim=1).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions using pre-trained inception_v3 model\n",
    "#     print('Computing predictions using inception v3 model')\n",
    "    \n",
    "\n",
    "    files = readDir()\n",
    "    N = len(files)\n",
    "    preds = np.zeros((N, 1000))\n",
    "    if batch_size > N:\n",
    "        print(('Warning: batch size is bigger than the data size. '\n",
    "                 'Setting batch size to data size'))\n",
    "\n",
    "    for i in tqdm(range(0, N, batch_size)):\n",
    "        start = i\n",
    "        end = i + batch_size\n",
    "        images = np.array([imread(str(f)).astype(np.float32)\n",
    "                           for f in files[start:end]])\n",
    "\n",
    "        # Reshape to (n_images, 3, height, width)\n",
    "        images = images.transpose((0, 3, 1, 2))\n",
    "        images /= 255\n",
    "\n",
    "        batch = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "        batch = batch\n",
    "        y = get_pred(batch)\n",
    "        print(y.shape)\n",
    "        preds[i :i  + batch_size] = get_pred(batch)\n",
    "        \n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "#     Now compute the mean KL Divergence\n",
    "    print('Computing KL Divergence')\n",
    "    split_scores = []\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k + 1) * (N // splits), :] # split the whole data into several parts\n",
    "        py = np.mean(part, axis=0)  # marginal probability\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]  # conditional probability\n",
    "            scores.append(entropy(pyx, py))  # compute divergence\n",
    "        split_scores.append(np.exp(scores))\n",
    "\n",
    "    return np.max(split_scores), np.mean(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59658328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDir():\n",
    "    dirPath = r\".../gan-fl/model-1/1\" #data path\n",
    "    allFiles = []\n",
    "    if os.path.isdir(dirPath):\n",
    "        fileList = os.listdir(dirPath)\n",
    "        for f in fileList:\n",
    "            f = dirPath+'/'+f\n",
    "            if os.path.isdir(f):\n",
    "                subFiles = readDir(f)\n",
    "                allFiles = subFiles + allFiles\n",
    "            else:\n",
    "                allFiles.append(f)\n",
    "        return allFiles\n",
    "    else:\n",
    "        return 'Error,not a dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b6239d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jackie\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jackie\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  3%|▎         | 1/30 [00:03<01:30,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [00:03<00:40,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [00:03<00:25,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [00:03<00:17,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [00:04<00:13,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [00:04<00:10,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [00:04<00:09,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [00:05<00:08,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [00:05<00:07,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [00:05<00:06,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [00:06<00:06,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [00:06<00:05,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [00:06<00:05,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [00:06<00:04,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [00:07<00:04,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [00:07<00:04,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [00:07<00:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [00:08<00:03,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [00:08<00:03,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [00:08<00:03,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [00:09<00:02,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [00:09<00:02,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [00:09<00:02,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [00:09<00:01,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [00:10<00:01,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [00:10<00:01,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [00:10<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [00:11<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [00:11<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n",
      "Computing KL Divergence\n",
      "MAX IS is 27.7722\n",
      "The IS is 2.4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX, IS= inception_score(splits=10)\n",
    "print('MAX IS is %.4f' % MAX)\n",
    "print('The IS is %.4f' % IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c48bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
