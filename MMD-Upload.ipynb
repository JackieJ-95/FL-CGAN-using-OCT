{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042da05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.datasets as dset\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchsummary import summary\n",
    "#os.chdir('D:/GANart/GAN-Artwork-Generation')\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17816569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    \"\"\"\n",
    "    source: sample_size_1 * feature_size original dataset \n",
    "    target: sample_size_2 * feature_size target dataset\n",
    "    kernel_mul: caculate every kernel bandwith\n",
    "    kernel_num: kernel_num\n",
    "    fix_sigma: fix_sigma \n",
    "\n",
    "\t\treturn: (sample_size_1 + sample_size_2) * (sample_size_1 + sample_size_2)的\n",
    "\t\t\t\t\t\tmatrix:\n",
    "\t\t\t\t\t\t[\tK_ss K_st\n",
    "\t\t\t\t\t\t\tK_ts K_tt ]\n",
    "    \"\"\"\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0) # cat function\n",
    "    \n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), \\ # 5 dimensions (1,batchsize,channel, width, height) \n",
    "                                       int(total.size(0)), \\ # single pictures only need 4 dimension \n",
    "                                       int(total.size(1)),\n",
    "                                    int(total.size(2)),\n",
    "                                      int(total.size(3)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), \\\n",
    "                                       int(total.size(0)), \\\n",
    "                                       int(total.size(1)),\n",
    "                                    int(total.size(2)),\n",
    "                                      int(total.size(3)))\n",
    "    L2_distance = ((total0-total1)**2).sum(4) # 计算高斯核中的|x-y|  #using guassian kernle to caculate \n",
    "#     print(L2_distance)\n",
    "    \n",
    "    # caculate every kernel bandwidth \n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "    \n",
    "    # exp(-|x-y|/bandwith)\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for \\\n",
    "                  bandwidth_temp in bandwidth_list]\n",
    "\n",
    "    return sum(kernel_val) \n",
    "  \n",
    "def mmd(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "                              kernel_mul=kernel_mul, \t\n",
    "                             \tkernel_num=kernel_num, \t\n",
    "                              fix_sigma=fix_sigma)\n",
    "#     print(kernels.shape)\n",
    "#     print(batch_size)\n",
    "    XX = kernels[:batch_size, :batch_size] # Source<->Source\n",
    "    YY = kernels[batch_size:, batch_size:] # Target<->Target\n",
    "    XY = kernels[:batch_size, batch_size:] # Source<->Target\n",
    "    YX = kernels[batch_size:, :batch_size] # Target<->Source\n",
    "    loss = torch.mean(XX + YY - XY -YX) \n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    data_1 = torch.tensor(np.random.normal(0,10,(100,50)))\n",
    "    data_2 = torch.tensor(np.random.normal(10,10,(100,50)))\n",
    "\n",
    "#     print(\"MMD Loss:\",mmd(data_1,data_2))\n",
    "\n",
    "    data_1 = torch.tensor(np.random.normal(0,10,(100,50)))\n",
    "    data_2 = torch.tensor(np.random.normal(0,9,(100,50)))\n",
    "\n",
    "#     print(\"MMD Loss:\",mmd(data_1,data_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc61f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"../gan-fl/bestfake\" #data path\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 1\n",
    "\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 4\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "#number of calsses lable \n",
    "n_class = 1\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator （output)\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epoc50\n",
    "num_epochs = 180\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0018\n",
    "\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf75494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4977734",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m savelist1\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# For each batch in the dataloader \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (data, real_style_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdataloader\u001b[49m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m## Train with all-real batch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# Format batch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         real_cpu \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m202\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "savelist1=[]\n",
    "for epoch in range(1):\n",
    "    # For each batch in the dataloader \n",
    "    for i, (data, real_style_labels) in enumerate(dataloader, 0):\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        \n",
    "        real_cpu = data.to(device)\n",
    "        if i<202:\n",
    "            savelist1.append(real_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdli=[]\n",
    "for i in range(200):\n",
    "    mmdloss=mmd(savelist[i],savelist1[i]) # original list and generate list\n",
    "    print(mmdloss)\n",
    "    mmdli.append(mmdloss.cpu().numpy())\n",
    "print('mean:',np.mean(mmdli))\n",
    "print('minimum:',np.min(mmdli))\n",
    "print('max:',np.max(mmdli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efd8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot2 = \"C:/Users/Jackie/Desktop/science/oct/disease6511\" #original dataset root\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 1\n",
    "\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 4\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "#number of calsses lable \n",
    "n_class = 1\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator （output)\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epoc50\n",
    "num_epochs = 180\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0018\n",
    "\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b62dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "dataset2 = dset.ImageFolder(root=dataroot2,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader2 = torch.utils.data.DataLoader(dataset2, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebe9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "savelist=[]\n",
    "for epoch in range(1):\n",
    "    # For each batch in the dataloader \n",
    "    for i, (data, real_style_labels) in enumerate(dataloader2, 0):\n",
    "\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        \n",
    "        real_cpu2 = data.to(device)\n",
    "        if i<202:\n",
    "#             print(real_cpu2)\n",
    "            savelist.append(real_cpu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64329518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m mmdli\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     mmdloss\u001b[38;5;241m=\u001b[39m\u001b[43mmmd\u001b[49m(savelist[i],savelist1[i])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(mmdloss)\n\u001b[0;32m      5\u001b[0m     mmdli\u001b[38;5;241m.\u001b[39mappend(mmdloss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mmd' is not defined"
     ]
    }
   ],
   "source": [
    "mmdli=[]\n",
    "for i in range(200):\n",
    "    mmdloss=mmd(savelist[i],savelist1[i])\n",
    "    print(mmdloss)\n",
    "    mmdli.append(mmdloss.cpu().numpy())\n",
    "print('mean:',np.mean(mmdli))\n",
    "print('minimum:',np.min(mmdli))\n",
    "print('max:',np.max(mmdli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ec63ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot10 = \"../gan-fl/netG-oct-4E-4000-fourth-1000-1-50-fake\" #generate dataset\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 1\n",
    "\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 4\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "#number of calsses lable \n",
    "n_class = 1\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator （output)\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epoc50\n",
    "num_epochs = 180\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0018\n",
    "\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dfd641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset10 = dset.ImageFolder(root=dataroot10,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader10 = torch.utils.data.DataLoader(dataset10, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "savelist10=[]\n",
    "for epoch in range(1):\n",
    "    # For each batch in the dataloader \n",
    "    for i, (data, real_style_labels) in enumerate(dataloader10, 0):\n",
    "    \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        \n",
    "        real_cpu10 = data.to(device)\n",
    "        if i<202:\n",
    "#             print(real_cpu2)\n",
    "            savelist10.append(real_cpu10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1625b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0041, device='cuda:0')\n",
      "tensor(0.0068, device='cuda:0')\n",
      "tensor(0.0058, device='cuda:0')\n",
      "tensor(0.0045, device='cuda:0')\n",
      "tensor(0.0115, device='cuda:0')\n",
      "tensor(0.0089, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0043, device='cuda:0')\n",
      "tensor(0.0036, device='cuda:0')\n",
      "tensor(0.0041, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0048, device='cuda:0')\n",
      "tensor(0.0072, device='cuda:0')\n",
      "tensor(0.0075, device='cuda:0')\n",
      "tensor(0.0087, device='cuda:0')\n",
      "tensor(0.0114, device='cuda:0')\n",
      "tensor(0.0047, device='cuda:0')\n",
      "tensor(0.0041, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0067, device='cuda:0')\n",
      "tensor(0.0134, device='cuda:0')\n",
      "tensor(0.0100, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0043, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0061, device='cuda:0')\n",
      "tensor(0.0031, device='cuda:0')\n",
      "tensor(0.0067, device='cuda:0')\n",
      "tensor(0.0048, device='cuda:0')\n",
      "tensor(0.0056, device='cuda:0')\n",
      "tensor(0.0042, device='cuda:0')\n",
      "tensor(0.0044, device='cuda:0')\n",
      "tensor(0.0043, device='cuda:0')\n",
      "tensor(0.0038, device='cuda:0')\n",
      "tensor(0.0060, device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0052, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0049, device='cuda:0')\n",
      "tensor(0.0058, device='cuda:0')\n",
      "tensor(0.0033, device='cuda:0')\n",
      "tensor(0.0045, device='cuda:0')\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0040, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0057, device='cuda:0')\n",
      "tensor(0.0107, device='cuda:0')\n",
      "tensor(0.0066, device='cuda:0')\n",
      "tensor(0.0029, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0059, device='cuda:0')\n",
      "tensor(0.0036, device='cuda:0')\n",
      "tensor(0.0061, device='cuda:0')\n",
      "tensor(0.0072, device='cuda:0')\n",
      "tensor(0.0094, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.0059, device='cuda:0')\n",
      "tensor(0.0056, device='cuda:0')\n",
      "tensor(0.0064, device='cuda:0')\n",
      "tensor(0.0060, device='cuda:0')\n",
      "tensor(0.0070, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.0043, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0040, device='cuda:0')\n",
      "tensor(0.0065, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0122, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0070, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.0115, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.0040, device='cuda:0')\n",
      "tensor(0.0087, device='cuda:0')\n",
      "tensor(0.0033, device='cuda:0')\n",
      "tensor(0.0045, device='cuda:0')\n",
      "tensor(0.0071, device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor(0.0047, device='cuda:0')\n",
      "tensor(0.0088, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0067, device='cuda:0')\n",
      "tensor(0.0024, device='cuda:0')\n",
      "tensor(0.0051, device='cuda:0')\n",
      "tensor(0.0091, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0072, device='cuda:0')\n",
      "tensor(0.0044, device='cuda:0')\n",
      "tensor(0.0060, device='cuda:0')\n",
      "tensor(0.0051, device='cuda:0')\n",
      "tensor(0.0051, device='cuda:0')\n",
      "tensor(0.0059, device='cuda:0')\n",
      "tensor(0.0071, device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor(0.0067, device='cuda:0')\n",
      "tensor(0.0043, device='cuda:0')\n",
      "tensor(0.0061, device='cuda:0')\n",
      "tensor(0.0093, device='cuda:0')\n",
      "tensor(0.0082, device='cuda:0')\n",
      "tensor(0.0035, device='cuda:0')\n",
      "tensor(0.0064, device='cuda:0')\n",
      "tensor(0.0039, device='cuda:0')\n",
      "tensor(0.0036, device='cuda:0')\n",
      "tensor(0.0060, device='cuda:0')\n",
      "tensor(0.0036, device='cuda:0')\n",
      "tensor(0.0094, device='cuda:0')\n",
      "tensor(0.0071, device='cuda:0')\n",
      "tensor(0.0052, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0046, device='cuda:0')\n",
      "tensor(0.0044, device='cuda:0')\n",
      "tensor(0.0062, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0070, device='cuda:0')\n",
      "tensor(0.0044, device='cuda:0')\n",
      "tensor(0.0099, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0072, device='cuda:0')\n",
      "tensor(0.0073, device='cuda:0')\n",
      "tensor(0.0068, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0044, device='cuda:0')\n",
      "tensor(0.0070, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0085, device='cuda:0')\n",
      "tensor(0.0058, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0058, device='cuda:0')\n",
      "tensor(0.0035, device='cuda:0')\n",
      "tensor(0.0063, device='cuda:0')\n",
      "tensor(0.0102, device='cuda:0')\n",
      "tensor(0.0042, device='cuda:0')\n",
      "tensor(0.0101, device='cuda:0')\n",
      "tensor(0.0066, device='cuda:0')\n",
      "tensor(0.0050, device='cuda:0')\n",
      "tensor(0.0090, device='cuda:0')\n",
      "tensor(0.0077, device='cuda:0')\n",
      "tensor(0.0059, device='cuda:0')\n",
      "tensor(0.0042, device='cuda:0')\n",
      "tensor(0.0108, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0')\n",
      "tensor(0.0057, device='cuda:0')\n",
      "tensor(0.0045, device='cuda:0')\n",
      "tensor(0.0083, device='cuda:0')\n",
      "tensor(0.0057, device='cuda:0')\n",
      "tensor(0.0070, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0066, device='cuda:0')\n",
      "tensor(0.0060, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0059, device='cuda:0')\n",
      "tensor(0.0049, device='cuda:0')\n",
      "tensor(0.0065, device='cuda:0')\n",
      "tensor(0.0071, device='cuda:0')\n",
      "tensor(0.0035, device='cuda:0')\n",
      "tensor(0.0089, device='cuda:0')\n",
      "tensor(0.0057, device='cuda:0')\n",
      "tensor(0.0049, device='cuda:0')\n",
      "tensor(0.0039, device='cuda:0')\n",
      "tensor(0.0049, device='cuda:0')\n",
      "tensor(0.0053, device='cuda:0')\n",
      "tensor(0.0041, device='cuda:0')\n",
      "tensor(0.0052, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0065, device='cuda:0')\n",
      "tensor(0.0038, device='cuda:0')\n",
      "tensor(0.0045, device='cuda:0')\n",
      "tensor(0.0068, device='cuda:0')\n",
      "tensor(0.0071, device='cuda:0')\n",
      "tensor(0.0078, device='cuda:0')\n",
      "tensor(0.0034, device='cuda:0')\n",
      "tensor(0.0056, device='cuda:0')\n",
      "tensor(0.0055, device='cuda:0')\n",
      "tensor(0.0080, device='cuda:0')\n",
      "tensor(0.0047, device='cuda:0')\n",
      "tensor(0.0054, device='cuda:0')\n",
      "tensor(0.0079, device='cuda:0')\n",
      "tensor(0.0074, device='cuda:0')\n",
      "tensor(0.0069, device='cuda:0')\n",
      "tensor(0.0030, device='cuda:0')\n",
      "mean: 0.006146565\n",
      "minimum: 0.0024253572\n",
      "max: 0.01341412\n"
     ]
    }
   ],
   "source": [
    "mmdli=[]\n",
    "for i in range(200):\n",
    "    mmdloss=mmd(savelist[i],savelist10[i])\n",
    "    print(mmdloss)\n",
    "    mmdli.append(mmdloss.cpu().numpy())\n",
    "print('mean:',np.mean(mmdli))\n",
    "print('minimum:',np.min(mmdli))\n",
    "print('max:',np.max(mmdli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9925f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
